{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import openai\n",
    "\n",
    "#azure_endpoint = os.environ[\"OPENAI_API_BASE\"],\n",
    "#openai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "#openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set the environment variable\n",
    "#os.environ.pop('OPENAI_API_BASE',None)\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"/\"\n",
    "#%env OPENAI_API_KEY=\"\"\n",
    "\n",
    "# Retrieve the value\n",
    "azure_endpoint = os.environ.get('AZURE_OPENAI_ENDPOINT')\n",
    "azure_openai_api_key = os.environ.get('AZURE_OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\" + d.page_content for i, d in enumerate(docs)]))\n",
    "\n",
    "   \n",
    "\n",
    "# Create an instance of AzureOpenAIEmbeddings with custom base URL\n",
    "#embedding = AzureOpenAIEmbeddings(azure_endpoint=azure_endpoint, openai_api_key=azure_openai_api_key,chunk_size=1)\n",
    "embedding = AzureOpenAIEmbeddings(chunk_size=1, model=\"text-embedding-3-large\")\n",
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load blog post\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./dogs.txt\")\n",
    "data = loader.load()\n",
    "loader = TextLoader(\"./restaurant.txt\")\n",
    "data2 = loader.load()\n",
    "\n",
    "docs = data + data2\n",
    "\n",
    "\n",
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=120, chunk_overlap=10)\n",
    "#docs = text_splitter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "vector1 = embedding.embed_query(\"How is the whether??\")\n",
    "vector2 = embedding.embed_query(\"What is the Name of the Dogschool?\")\n",
    "vector3 = embedding.embed_query(\"What food do you offer?\")\n",
    "\n",
    "data_vectors = [embedding.embed_query(doc.page_content) for doc in docs]\n",
    "print(len(data_vectors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cosine_sims_1 = [cosine_similarity([vector1], [data_vector])[0][0] for data_vector in data_vectors]\n",
    "cosine_sims_2 = [cosine_similarity([vector2], [data_vector])[0][0] for data_vector in data_vectors]\n",
    "cosine_sims_3 = [cosine_similarity([vector3], [data_vector])[0][0] for data_vector in data_vectors]\n",
    "\n",
    "x = np.arange(len(data_vectors))\n",
    "\n",
    "plt.scatter(x, cosine_sims_1, label='Weather', alpha=0.7)\n",
    "plt.scatter(x, cosine_sims_2, label='Dogschool', alpha=0.7)\n",
    "plt.scatter(x, cosine_sims_3, label='Restaurant', alpha=0.7)\n",
    "\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.title('Consine Similarity between query and data vectors')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hepzibah.prema\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=120, chunk_overlap=20)\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=embedding\n",
    ")\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A1: The school is called \"Canine Academy\".', metadata={'doc_id': '36286fb3-6276-46d2-86c5-ed639ba2adad', 'source': './dogs.txt'}),\n",
       " Document(page_content='Fiktive Hundeschule: Canine Academy\\nQ1: What is the name of the dog training school?', metadata={'doc_id': '36286fb3-6276-46d2-86c5-ed639ba2adad', 'source': './dogs.txt'}),\n",
       " Document(page_content='Q3: What training programs are offered at Canine Academy?', metadata={'doc_id': '36286fb3-6276-46d2-86c5-ed639ba2adad', 'source': './dogs.txt'}),\n",
       " Document(page_content='Q9: What are the fees for the training courses at Canine Academy?', metadata={'doc_id': '6058ed05-f03c-4da4-ad44-c4c6e2464825', 'source': './dogs.txt'})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"What is the name of the dog school?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved relevant documents!\n",
      "[Document(page_content='Fiktive Hundeschule: Canine Academy\\nQ1: What is the name of the dog training school?\\nA1: The school is called \"Canine Academy\".\\n\\nQ2: Where is Canine Academy located?\\nA2: Canine Academy is located in the suburbs, near the community park.\\n\\nQ3: What training programs are offered at Canine Academy?\\nA3: They offer basic obedience, agility training, and advanced behavioral courses.', metadata={'source': './dogs.txt'}), Document(page_content=\"Q8: Is there a trial class or evaluation session available?\\nA8: Yes, they offer a free evaluation session to assess the dog's needs and training level.\\n\\nQ9: What are the fees for the training courses at Canine Academy?\\nA9: Fees vary based on the course, but they offer competitive rates and package deals.\", metadata={'source': './dogs.txt'})]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def get_relevant_documents_with_retry(retriever, query, max_retries=3, delay=1):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            relevant_docs = retriever.get_relevant_documents(query)\n",
    "            return relevant_docs\n",
    "        except Exception as e:\n",
    "            print(f\"Encountered exception: {e}. Retrying...\")\n",
    "            retries += 1\n",
    "            time.sleep(delay)\n",
    "    return None  # Return None if all retries fail\n",
    "\n",
    "# Example usage:\n",
    "query = \"What is the name of the dog school?\"\n",
    "try:\n",
    "    relevant_docs = get_relevant_documents_with_retry(retriever, query)\n",
    "    if relevant_docs is not None:\n",
    "        print(\"Successfully retrieved relevant documents!\")\n",
    "        print(relevant_docs)\n",
    "    else:\n",
    "        print(\"Failed to retrieve relevant documents after max retries.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to retrieve relevant documents: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiQueryRetriever\n",
    "\n",
    "Nuances in the question can lead to different results if the question does not capture the embeddings semantically well.\n",
    "MultiQueryRetriever creates variations of the question and thus goes against the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "llm = ChatOpenAI(      \n",
    "         \n",
    "        openai_api_key=\"\",\n",
    "        temperature=0,\n",
    "        max_tokens=800,\n",
    "        model_kwargs={\"top_p\": 0, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    "        \n",
    "    )\n",
    "\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs = retriever.get_relevant_documents(\"What is the name of the dog school?\")\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\noutput_parser\n  instance of BaseLLMOutputParser expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseLLMOutputParser)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m\n\u001b[0;32m     10\u001b[0m QUERY_PROMPT \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m     11\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     12\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are an AI language model assistant. Your task is to generate five\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m    Original question: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Initialize the language model chain with the prompt and output parser\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQUERY_PROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLineList\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Invoke the language model chain with the input question\u001b[39;00m\n\u001b[0;32m     24\u001b[0m response \u001b[38;5;241m=\u001b[39m llm_chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the name of the dog school?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\load\\serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for LLMChain\noutput_parser\n  instance of BaseLLMOutputParser expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseLLMOutputParser)"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class LineList(BaseModel):\n",
    "    lines: List[str] = Field(description=\"Lines of text\")\n",
    "\n",
    "# Define a prompt template for the query\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from a vector\n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search.\n",
    "    Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "# Initialize the language model chain with the prompt and output parser\n",
    "llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT, output_parser=LineList)\n",
    "\n",
    "# Invoke the language model chain with the input question\n",
    "response = llm_chain.invoke(\"What is the name of the dog school?\")\n",
    "\n",
    "# Print the parsed response\n",
    "print(\"Parsed response:\")\n",
    "print(response.lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mllm_chain\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the name of the dog school?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm_chain' is not defined"
     ]
    }
   ],
   "source": [
    "llm_chain.invoke(\"What is the name of the dog school?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the name of the dog school?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Compression\n",
    "\n",
    "To use the Contextual Compression Retriever, you need:\n",
    "\n",
    "    a basic retriever\n",
    "    a document compressor\n",
    "\n",
    "The Contextual Compression Retriever passes queries to the Base Retriever, takes the source documents and forwards them to the Document Compressor. The document compressor takes a list of documents and shortens them by reducing the content of documents or omitting documents altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=embedding\n",
    ")\n",
    "vectorstore.add_documents(docs)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A1: The school is called \"Canine Academy\".', metadata={'doc_id': '36286fb3-6276-46d2-86c5-ed639ba2adad', 'source': './dogs.txt'}),\n",
       " Document(page_content='Fiktive Hundeschule: Canine Academy\\nQ1: What is the name of the dog training school?', metadata={'doc_id': '36286fb3-6276-46d2-86c5-ed639ba2adad', 'source': './dogs.txt'}),\n",
       " Document(page_content='Fiktive Hundeschule: Canine Academy\\nQ1: What is the name of the dog training school?\\nA1: The school is called \"Canine Academy\".\\n\\nQ2: Where is Canine Academy located?\\nA2: Canine Academy is located in the suburbs, near the community park.\\n\\nQ3: What training programs are offered at Canine Academy?\\nA3: They offer basic obedience, agility training, and advanced behavioral courses.\\n\\nQ4: Are there any special qualifications for the trainers at Canine Academy?\\nA4: All trainers are certified and have years of experience in dog training and behavior.\\n\\nQ5: Can Canine Academy help with specific behavioral issues?\\nA5: Yes, they offer personalized training sessions for issues like aggression, anxiety, and barking.\\n\\nQ6: How long do the training courses last?\\nA6: The courses vary, ranging from 4-week short courses to 12-week intensive programs.\\n\\nQ7: Does Canine Academy provide training for service or therapy dogs?\\nA7: Yes, they have specialized programs for service and therapy dog training.\\n\\nQ8: Is there a trial class or evaluation session available?\\nA8: Yes, they offer a free evaluation session to assess the dog\\'s needs and training level.\\n\\nQ9: What are the fees for the training courses at Canine Academy?\\nA9: Fees vary based on the course, but they offer competitive rates and package deals.\\n\\nQ10: Does Canine Academy offer any support or follow-up after completion of a course?\\nA10: Yes, they provide follow-up consultations and support for continued training and development.', metadata={'source': './dogs.txt'}),\n",
       " Document(page_content='Q3: What training programs are offered at Canine Academy?', metadata={'doc_id': '36286fb3-6276-46d2-86c5-ed639ba2adad', 'source': './dogs.txt'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hepzibah.prema\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hepzibah.prema\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hepzibah.prema\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hepzibah.prema\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "The school is called \"Canine Academy\".\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "Fiktive Hundeschule: Canine Academy\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "Fiktive Hundeschule: Canine Academy\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query=question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "A1: The school is called \"Canine Academy\".\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "Fiktive Hundeschule: Canine Academy\n",
      "Q1: What is the name of the dog training school?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "Fiktive Hundeschule: Canine Academy\n",
      "Q1: What is the name of the dog training school?\n",
      "A1: The school is called \"Canine Academy\".\n",
      "\n",
      "Q2: Where is Canine Academy located?\n",
      "A2: Canine Academy is located in the suburbs, near the community park.\n",
      "\n",
      "Q3: What training programs are offered at Canine Academy?\n",
      "A3: They offer basic obedience, agility training, and advanced behavioral courses.\n",
      "\n",
      "Q4: Are there any special qualifications for the trainers at Canine Academy?\n",
      "A4: All trainers are certified and have years of experience in dog training and behavior.\n",
      "\n",
      "Q5: Can Canine Academy help with specific behavioral issues?\n",
      "A5: Yes, they offer personalized training sessions for issues like aggression, anxiety, and barking.\n",
      "\n",
      "Q6: How long do the training courses last?\n",
      "A6: The courses vary, ranging from 4-week short courses to 12-week intensive programs.\n",
      "\n",
      "Q7: Does Canine Academy provide training for service or therapy dogs?\n",
      "A7: Yes, they have specialized programs for service and therapy dog training.\n",
      "\n",
      "Q8: Is there a trial class or evaluation session available?\n",
      "A8: Yes, they offer a free evaluation session to assess the dog's needs and training level.\n",
      "\n",
      "Q9: What are the fees for the training courses at Canine Academy?\n",
      "A9: Fees vary based on the course, but they offer competitive rates and package deals.\n",
      "\n",
      "Q10: Does Canine Academy offer any support or follow-up after completion of a course?\n",
      "A10: Yes, they provide follow-up consultations and support for continued training and development.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "Q3: What training programs are offered at Canine Academy?\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embedding, similarity_threshold=0.5)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=embeddings_filter, base_retriever=retriever)\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query=question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0, separator=\". \")\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embedding)\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embedding, similarity_threshold=0.76)\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter, redundant_filter, relevant_filter]\n",
    ")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=pipeline_compressor, base_retriever=retriever)\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query=question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "chroma_vectorstore = Chroma.from_documents(docs, embedding)\n",
    "chroma_retriever = chroma_vectorstore.as_retriever()\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Fiktive Hundeschule: Canine Academy\\nQ1: What is the name of the dog training school?\\nA1: The school is called \"Canine Academy\".\\n\\nQ2: Where is Canine Academy located?\\nA2: Canine Academy is located in the suburbs, near the community park.\\n\\nQ3: What training programs are offered at Canine Academy?\\nA3: They offer basic obedience, agility training, and advanced behavioral courses.\\n\\nQ4: Are there any special qualifications for the trainers at Canine Academy?\\nA4: All trainers are certified and have years of experience in dog training and behavior.\\n\\nQ5: Can Canine Academy help with specific behavioral issues?\\nA5: Yes, they offer personalized training sessions for issues like aggression, anxiety, and barking.\\n\\nQ6: How long do the training courses last?\\nA6: The courses vary, ranging from 4-week short courses to 12-week intensive programs.\\n\\nQ7: Does Canine Academy provide training for service or therapy dogs?\\nA7: Yes, they have specialized programs for service and therapy dog training.\\n\\nQ8: Is there a trial class or evaluation session available?\\nA8: Yes, they offer a free evaluation session to assess the dog\\'s needs and training level.\\n\\nQ9: What are the fees for the training courses at Canine Academy?\\nA9: Fees vary based on the course, but they offer competitive rates and package deals.\\n\\nQ10: Does Canine Academy offer any support or follow-up after completion of a course?\\nA10: Yes, they provide follow-up consultations and support for continued training and development.', metadata={'source': './dogs.txt'}),\n",
       " Document(page_content='Fiktives Restaurant: Gourmet\\'s Delight\\nQ1: What is the name of the restaurant?\\nA1: The restaurant is named \"Gourmet\\'s Delight\".\\n\\nQ2: Where is Gourmet\\'s Delight located?\\nA2: It is located in the heart of downtown, on Maple Street.\\n\\nQ3: What type of cuisine does Gourmet\\'s Delight offer?\\nA3: Gourmet\\'s Delight specializes in a fusion of Mediterranean and Asian cuisine.\\n\\nQ4: Is the restaurant vegetarian-friendly?\\nA4: Yes, there is a wide range of vegetarian and vegan options available.\\n\\nQ5: Does Gourmet\\'s Delight accept reservations?\\nA5: Yes, guests are encouraged to make reservations, especially on weekends.\\n\\nQ6: Are there any special dishes that are recommended at Gourmet\\'s Delight?\\nA6: The signature dish is the \\'Medit-Asian Fusion Platter\\' which includes a variety of specialties.\\n\\nQ7: What are the operating hours of the restaurant?\\nA7: The restaurant is open from 11:00 AM to 10:00 PM, Monday through Sunday.\\n\\nQ8: Does Gourmet\\'s Delight offer any special promotions?\\nA8: Yes, there are happy hour discounts from 4:00 PM to 6:00 PM on weekdays.\\n\\nQ9: Can Gourmet\\'s Delight accommodate large parties or events?\\nA9: Yes, the restaurant has a private dining area that can be reserved for events and parties.', metadata={'source': './restaurant.txt'})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ensemble_retriever.get_relevant_documents(query=question)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Querying retriever\n",
    "\n",
    "A self-querying retriever is a retriever that, as the name suggests, has the ability to \n",
    "the ability to query itself. More precisely, any natural language query,\n",
    " the retriever uses an LLM chain for query construction to write a structured query\n",
    " structured query and then applies this structured query to the underlying \n",
    "VectorStore. This allows the retriever to not only use the query entered by the user \n",
    "query for the semantic similarity comparison with the content of the stored \n",
    "documents, but also apply filters from the user query to the metadata of the stored \n",
    "metadata of the stored documents and execute these filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Bello-Basistraining offers a comprehensive foundation for dog obedience, focusing on basic commands and socialization.\",\n",
    "        metadata={\"type\": \"Basic Training\", \"feature\": \"Foundational Skills\", \"price\": \"Affordable\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Pfote-Agilitykurs provides a fun and energetic way to keep dogs fit and mentally stimulated through obstacle courses.\",\n",
    "        metadata={\"type\": \"Agility Training\", \"feature\": \"Physical Fitness\", \"price\": \"Moderate\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Wuff-Verhaltensberatung specializes in addressing behavioral issues, offering tailored strategies for each dog.\",\n",
    "        metadata={\"type\": \"Behavioral Consultation\", \"feature\": \"Customized Solutions\", \"price\": \"Premium\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Schwanzwedeln-Therapiehundausbildung prepares dogs for roles in therapeutic and support settings, focusing on empathy and gentleness.\",\n",
    "        metadata={\"type\": \"Therapy Dog Training\", \"feature\": \"Emotional Support\", \"price\": \"High\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Schnüffler-Suchhundetraining trains dogs in scent detection, useful for search and rescue operations.\",\n",
    "        metadata={\"type\": \"Search and Rescue Training\", \"feature\": \"Advanced Skills\", \"price\": \"Variable\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Hunde-Haftpflichtversicherung offers comprehensive coverage for potential damages or injuries caused by your dog.\",\n",
    "        metadata={\"type\": \"Dog Liability Insurance\", \"feature\": \"Financial Protection\", \"price\": \"Varies\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"type\",\n",
    "        description=\"The type of dog training service (e.g., Basic Training, Agility Training, Behavioral Consultation)\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"feature\",\n",
    "        description=\"Special features or benefits of the service\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"price\",\n",
    "        description=\"Price category of the service (e.g., Affordable, Moderate, Premium)\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Description of a dog training service\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Wuff-Verhaltensberatung specializes in addressing behavioral issues, offering tailored strategies for each dog.', metadata={'feature': 'Customized Solutions', 'price': 'Premium', 'type': 'Behavioral Consultation'})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What Premium priced trainings do you offer?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-weighted vector store retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decay_rate = .0000000000000000000000001\n",
    "decay_rate = .999\n",
    "\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embedding, index, InMemoryDocstore({}), {})\n",
    "retriever = TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, decay_rate=decay_rate, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def call_openai_api_with_retry(api_function, *args, **kwargs):\n",
    "    max_retries = 5  # Adjust the maximum number of retries as needed\n",
    "    base_delay = 30  # seconds (adjust according to your preference)\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            return api_function(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            if \"Rate limit reached\" in str(e):  # Check if the error message contains \"Rate limit reached\"\n",
    "                delay = base_delay * 2**retries\n",
    "                print(f\"Rate limit reached. Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                retries += 1\n",
    "            else:\n",
    "                raise e\n",
    "    raise Exception(\"Max retries reached. Failed to call OpenAI API.\")\n",
    "\n",
    "# Usage example:\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "try:\n",
    "    retriever.add_documents([Document(page_content=\"hello world\", metadata={\"last_accessed_at\": yesterday})])\n",
    "    retriever.add_documents([Document(page_content=\"hello foo\")])\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhello world\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\retrievers.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    244\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    248\u001b[0m         result,\n\u001b[0;32m    249\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\retrievers.py:238\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 238\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\retrievers\\time_weighted_retriever.py:137\u001b[0m, in \u001b[0;36mTimeWeightedVectorStoreRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m    132\u001b[0m docs_and_scores \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    133\u001b[0m     doc\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffer_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m]: (doc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_salience)\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_stream[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk :]\n\u001b[0;32m    135\u001b[0m }\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# If a doc is considered salient, update the salience score\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m docs_and_scores\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_salient_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rescored_docs(docs_and_scores)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\retrievers\\time_weighted_retriever.py:84\u001b[0m, in \u001b[0;36mTimeWeightedVectorStoreRetriever.get_salient_docs\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return documents that are salient to the query.\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m docs_and_scores: List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]\n\u001b[1;32m---> 84\u001b[0m docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fetched_doc, relevance \u001b[38;5;129;01min\u001b[39;00m docs_and_scores:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\vectorstores.py:323\u001b[0m, in \u001b[0;36mVectorStore.similarity_search_with_relevance_scores\u001b[1;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs and relevance scores in the range [0, 1].\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m0 is dissimilar, 1 is most similar.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03m    List of Tuples of (doc, similarity_score)\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    321\u001b[0m score_threshold \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 323\u001b[0m docs_and_similarities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_similarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    327\u001b[0m     similarity \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m similarity \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, similarity \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities\n\u001b[0;32m    329\u001b[0m ):\n\u001b[0;32m    330\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelevance scores must be between\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m 0 and 1, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocs_and_similarities\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    333\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1159\u001b[0m, in \u001b[0;36mFAISS._similarity_search_with_relevance_scores\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relevance_score_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize_score_fn must be provided to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m FAISS constructor to normalize scores\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1158\u001b[0m     )\n\u001b[1;32m-> 1159\u001b[0m docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m docs_and_rel_scores \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1167\u001b[0m     (doc, relevance_score_fn(score)) \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m docs_and_scores\n\u001b[0;32m   1168\u001b[0m ]\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m docs_and_rel_scores\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:403\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_query(query)\n\u001b[1;32m--> 403\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score_by_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:304\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score_by_vector\u001b[1;34m(self, embedding, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_L2:\n\u001b[0;32m    303\u001b[0m     faiss\u001b[38;5;241m.\u001b[39mnormalize_L2(vector)\n\u001b[1;32m--> 304\u001b[0m scores, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m docs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\faiss\\class_wrappers.py:329\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[1;34m(self, x, k, params, D, I)\u001b[0m\n\u001b[0;32m    327\u001b[0m n, d \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    328\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m k \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m D \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
